{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "flow",
   "display_name": "flow",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"HeadlineData.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of         headline_nr                                           headline label\n0                 0  There Were 2 Mass Shootings In Texas Last Week...     N\n1                 1  Will Smith Joins Diplo And Nicky Jam For The 2...     O\n2                 2    Hugh Grant Marries For The First Time At Age 57     O\n3                 3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...     O\n4                 4  Julianna Margulies Uses Donald Trump Poop Bags...     O\n...             ...                                                ...   ...\n150146       150146                                   Complicated Cuba     o\n150147       150147               Your Pets, Eating Ice Cream (PHOTOS)     p\n150148       150148  First Look' Photos That Will Make You Believe ...     p\n150149       150149      Recommendations for Avoiding Toxic Pet Treats     o\n150150       150150   The Best Fast-Food Burger: A HuffPost Deathmatch     o\n\n[2021 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of         headline_nr                                           headline label\n0                 0  there were 2 mass shootings in texas last week...     n\n1                 1  will smith joins diplo and nicky jam for the 2...     o\n2                 2    hugh grant marries for the first time at age 57     o\n3                 3  jim carrey blasts 'castrato' adam schiff and d...     o\n4                 4  julianna margulies uses donald trump poop bags...     o\n...             ...                                                ...   ...\n150146       150146                                   complicated cuba     o\n150147       150147               your pets, eating ice cream (photos)     p\n150148       150148  first look' photos that will make you believe ...     p\n150149       150149      recommendations for avoiding toxic pet treats     o\n150150       150150   the best fast-food burger: a huffpost deathmatch     o\n\n[2021 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"] = df[\"label\"].str.lower()\n",
    "df[\"headline\"] = df[\"headline\"].str.lower()\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of         headline_nr                                           headline label\n0                 0  there were  mass shootings in texas last week ...     n\n1                 1  will smith joins diplo and nicky jam for the  ...     o\n2                 2      hugh grant marries for the first time at age      o\n3                 3  jim carrey blasts castrato adam schiff and dem...     o\n4                 4  julianna margulies uses donald trump poop bags...     o\n...             ...                                                ...   ...\n150146       150146                                   complicated cuba     o\n150147       150147                  your pets eating ice cream photos     p\n150148       150148  first look photos that will make you believe i...     p\n150149       150149      recommendations for avoiding toxic pet treats     o\n150150       150150    the best fast-food burger a huffpost deathmatch     o\n\n[2021 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df['headline'] = df['headline'].str.replace(',', '')\n",
    "df['headline'] = df['headline'].str.replace(':', '')\n",
    "df['headline'] = df['headline'].str.replace('.', '')\n",
    "df['headline'] = df['headline'].str.replace(';', '')\n",
    "df['headline'] = df['headline'].str.replace(\"'\", '')\n",
    "df['headline'] = df['headline'].str.replace('?', '')\n",
    "df['headline'] = df['headline'].str.replace('!', '')\n",
    "df['headline'] = df['headline'].str.replace('*', '')\n",
    "df['headline'] = df['headline'].str.replace('(', '')\n",
    "df['headline'] = df['headline'].str.replace(')', '')\n",
    "df['headline'] = df['headline'].str.replace('/', '')\n",
    "df['headline'] = df['headline'].str.replace(\"`\", '')\n",
    "df['headline'] = df['headline'].str.replace(\"´\", '')\n",
    "df['headline'] = df['headline'].str.replace(\"‘\", '')\n",
    "df['headline'] = df['headline'].str.replace(\"’\", '')\n",
    "df['headline'] = df['headline'].str.replace('\\d+', '')\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"headline\"] = df[\"headline\"].str.split(pat=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of         headline_nr                                           headline label\n0                 0  [there, were, , mass, shootings, in, texas, la...     n\n1                 1  [will, smith, joins, diplo, and, nicky, jam, f...     o\n2                 2  [hugh, grant, marries, for, the, first, time, ...     o\n3                 3  [jim, carrey, blasts, castrato, adam, schiff, ...     o\n4                 4  [julianna, margulies, uses, donald, trump, poo...     o\n...             ...                                                ...   ...\n150146       150146                                [complicated, cuba]     o\n150147       150147           [your, pets, eating, ice, cream, photos]     p\n150148       150148  [first, look, photos, that, will, make, you, b...     p\n150149       150149  [recommendations, for, avoiding, toxic, pet, t...     o\n150150       150150  [the, best, fast-food, burger, a, huffpost, de...     o\n\n[2021 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTraining=df[:1600]\n",
    "dfTesting=df[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method NDFrame.head of         headline_nr                                           headline label\n0                 0  [there, were, , mass, shootings, in, texas, la...     n\n1                 1  [will, smith, joins, diplo, and, nicky, jam, f...     o\n2                 2  [hugh, grant, marries, for, the, first, time, ...     o\n3                 3  [jim, carrey, blasts, castrato, adam, schiff, ...     o\n4                 4  [julianna, margulies, uses, donald, trump, poo...     o\n...             ...                                                ...   ...\n108226       108226  [the, seemingly-virtuous, often-dangerous, wor...     o\n108227       108227  [game-changing, plays, from, week, , in, the, ...     o\n108228       108228  [the, art, of, growing, old, how, does, anyone...     p\n108229       108229  [koko, jones, former, percussionist, for, whit...     o\n108230       108230          [can, we, make, people, want, to, change]     o\n\n[1600 rows x 3 columns]>\n<bound method NDFrame.head of         headline_nr                                           headline label\n108231       108231  [my, mother, re-formed, her, rock, band, --, a...     p\n108232       108232  [why, the, story, of, muhammad, alis, rebellio...     p\n108233       108233        [process, rules, are, made, to, be, broken]     p\n108234       108234  [, things, i, didnt, need, to, raise, a, child...     o\n108235       108235  [project, , a, portrait, of, millennial, artis...     o\n...             ...                                                ...   ...\n150146       150146                                [complicated, cuba]     o\n150147       150147           [your, pets, eating, ice, cream, photos]     p\n150148       150148  [first, look, photos, that, will, make, you, b...     p\n150149       150149  [recommendations, for, avoiding, toxic, pet, t...     o\n150150       150150  [the, best, fast-food, burger, a, huffpost, de...     o\n\n[421 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(dfTraining.head)\n",
    "print(dfTesting.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(dfTraining):\n",
    "    for i in dfTraining[\"headline\"]:\n",
    "        for word in i:\n",
    "            if word in Vocabulary:\n",
    "                continue\n",
    "            else:\n",
    "                Vocabulary.append(word)\n",
    "\n",
    "    TrainingDocs = len(dfTraining[\"headline\"])\n",
    "    VSize = len(Vocabulary)\n",
    "    print(\"Training with \",TrainingDocs,\" Headlines and \", VSize,\" unique Words\")\n",
    "\n",
    "    TrainingPos = dfTraining[dfTraining[\"label\"]==\"p\"].count()\n",
    "    TrainingNeg = dfTraining[dfTraining[\"label\"]==\"n\"].count()\n",
    "    TrainingNeu = dfTraining[dfTraining[\"label\"]==\"o\"].count()\n",
    "    print(\"Positive: \",TrainingPos[\"label\"])\n",
    "    print(\"Negative: \",TrainingNeg[\"label\"])\n",
    "    print(\"Neutral: \",TrainingNeu[\"label\"])\n",
    "\n",
    "    PriorPos = np.log(TrainingPos[\"label\"]/TrainingDocs)\n",
    "    PriorNeg = np.log(TrainingNeg[\"label\"]/TrainingDocs)\n",
    "    PriorNeu = np.log(TrainingNeu[\"label\"]/TrainingDocs)\n",
    "\n",
    "    #for Vword in Vocabulary:\n",
    "        #for line in TrainingPos[\"headline\"]:\n",
    "            #for Element in line:\n",
    "    print(PriorNeu)\n",
    "    print(PriorNeg)\n",
    "    print(PriorPos)\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                 there\n1                  will\n2                  hugh\n3                   jim\n4              julianna\n              ...      \n108226              the\n108227    game-changing\n108228              the\n108229             koko\n108230              can\nName: headline, Length: 1600, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Vocabulary =[]\n",
    "print(dfTraining[\"headline\"].str[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training with  1600  Headlines and  5333  unique Words\nPositive:  331\nNegative:  595\nNeutral:  674\n-0.8645287973155655\n-0.9891975026822428\n-1.5756405328508096\n"
     ]
    }
   ],
   "source": [
    "train_naive_bayes(dfTraining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5333\n"
     ]
    }
   ],
   "source": [
    "print(V_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": []
  }
 ]
}